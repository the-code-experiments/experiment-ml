{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Filter Method\n",
    "\n",
    "* Selection of variables are indenendant of the ML model and instead it rely on the characteristics of the data.\n",
    "\n",
    "## Pros\n",
    "\n",
    "* Less computationally expensive.\n",
    "* Well suited for a quick removal of irrelevant features.\n",
    "* Model agnostic, means the features subset can be use in any ML models.\n",
    "\n",
    "## Cors\n",
    "\n",
    "* Lower prediction performance as compared to wrapper method.\n",
    "\n",
    "\n",
    "## Steps in filter method\n",
    "\n",
    "Consist of 2 steps:\n",
    "\n",
    "1. Rank features based on certain criteria.\n",
    "2. Select the highest ranking features.\n",
    "\n",
    "Each feature is ranked independently of the other features/feature space because of which it may result in rendendent variables, as they do not consider the relationship between features.\n",
    "\n",
    "**Ranking Criteria** relies on various statistical tests like:\n",
    "\n",
    "* Chi-square | Fisher score\n",
    "* Univariate parameteric tests\n",
    "* Mutual information\n",
    "* Variance\n",
    "    \n",
    "    * Constant features\n",
    "    * Quasi-constant features\n",
    "\n",
    "## General usage\n",
    "\n",
    "Filter selection will help to remove:\n",
    "\n",
    "1. Constant features\n",
    "2. Quasi-constant features\n",
    "3. Duplicated features, which may arise after one-hot encoding of categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Constant features:\n",
    "\n",
    "* Are those that show the just one value for all the observations of the dataset.\n",
    "* The same value for all the rows of the dataset.\n",
    "* These features provide no info that allows a ML model to predict a target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1 - Customer transaction prediction\n",
    "\n",
    "Lets remove constant features by loading a dataset and check the presence of null data.\n",
    "\n",
    "References:\n",
    "\n",
    "* https://www.kaggle.com/raviprakash438/filter-method-feature-selection/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 371)\n",
      "(7000, 370) (3000, 370)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\"\"\"\n",
    "Load the 10000 rows from the datasets\n",
    "\"\"\"\n",
    "data = pd.read_csv(\"./_datasets_/customer-transaction.csv\", nrows=10000)\n",
    "print(data.shape)\n",
    "\n",
    "\"\"\"\n",
    "Update the loaded data by removing all the null values from the dataset's columns\n",
    "\"\"\"\n",
    "[col for col in data.columns if data[col].isnull().sum() > 0]\n",
    "\n",
    "\"\"\"\n",
    "Split the datasets into training set (70%) and test set (30%)\n",
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['TARGET'], axis=1),\n",
    "    data['TARGET'],\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- Sklearn's variance threshold is a simple baseline approach for feature selection.\n",
    "- It removes all features which variance doesn't meet some threshold.\n",
    "- By default, it removes all zero-variance features i.e. features that have the same value in all samples.\n",
    "\n",
    "This feature selection algorithm looks only at the features (X), not the desired outputs(y).\n",
    "\n",
    "Reference:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html\n",
    "\"\"\"\n",
    "f_sel = VarianceThreshold(threshold=0)\n",
    "\n",
    "f_sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False False\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False False  True  True  True  True  True False False  True  True\n",
      "  True  True  True  True  True  True  True  True  True False False False\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      " False False  True  True  True  True  True  True  True False  True  True\n",
      "  True False False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False False  True  True  True\n",
      "  True  True False False  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False False False False  True  True  True  True  True  True  True  True\n",
      "  True  True False False  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True False False  True  True  True  True\n",
      "  True  True  True False  True  True  True False  True  True  True  True\n",
      " False False  True  True  True  True  True False  True  True False  True\n",
      "  True False  True False False  True  True  True  True  True False False\n",
      "  True False  True False  True  True  True  True  True  True False False\n",
      "  True False  True False  True False False False False  True  True  True\n",
      "  True  True  True False  True  True  True False  True False False False\n",
      " False  True  True False  True False False False  True False False False\n",
      "  True False  True  True  True  True  True  True  True  True False False\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False  True False False False False  True  True\n",
      "  True  True False  True False False False  True False False False  True\n",
      "  True  True  True  True False  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False False False False  True  True  True  True False False  True\n",
      "  True  True  True  True  True  True  True  True  True  True]\n",
      "Counter({True: 284, False: 86})\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- get_support return True and False value for each feature.\n",
    "- True: Not a constant feature\n",
    "- False: Constant feature(It contains same value in all samples.)\n",
    "\"\"\"\n",
    "s = f_sel.get_support()\n",
    "print(s)\n",
    "\n",
    "\"\"\"\n",
    "Find total number of constant and non-constant features\n",
    "\"\"\"\n",
    "import collections\n",
    "print(collections.Counter(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_var2_0', 'ind_var2', 'ind_var13_medio_0', 'ind_var13_medio', 'ind_var18_0', 'ind_var18', 'ind_var27_0', 'ind_var28_0', 'ind_var28', 'ind_var27', 'ind_var34_0', 'ind_var34', 'ind_var41', 'ind_var46_0', 'ind_var46', 'num_var13_medio_0', 'num_var13_medio', 'num_var18_0', 'num_var18', 'num_var27_0', 'num_var28_0', 'num_var28', 'num_var27', 'num_var34_0', 'num_var34', 'num_var41', 'num_var46_0', 'num_var46', 'saldo_var13_medio', 'saldo_var18', 'saldo_var28', 'saldo_var27', 'saldo_var34', 'saldo_var41', 'saldo_var46', 'delta_imp_amort_var18_1y3', 'delta_imp_amort_var34_1y3', 'delta_imp_reemb_var17_1y3', 'delta_imp_reemb_var33_1y3', 'delta_imp_trasp_var17_out_1y3', 'delta_imp_trasp_var33_out_1y3', 'delta_num_reemb_var17_1y3', 'delta_num_reemb_var33_1y3', 'delta_num_trasp_var17_out_1y3', 'delta_num_trasp_var33_out_1y3', 'imp_amort_var18_hace3', 'imp_amort_var18_ult1', 'imp_amort_var34_hace3', 'imp_amort_var34_ult1', 'imp_var7_emit_ult1', 'imp_reemb_var13_hace3', 'imp_reemb_var17_hace3', 'imp_reemb_var17_ult1', 'imp_reemb_var33_hace3', 'imp_reemb_var33_ult1', 'imp_trasp_var17_in_hace3', 'imp_trasp_var17_out_hace3', 'imp_trasp_var17_out_ult1', 'imp_trasp_var33_in_hace3', 'imp_trasp_var33_out_hace3', 'imp_trasp_var33_out_ult1', 'imp_venta_var44_hace3', 'ind_var7_emit_ult1', 'num_var2_0_ult1', 'num_var2_ult1', 'num_var7_emit_ult1', 'num_meses_var13_medio_ult3', 'num_reemb_var13_hace3', 'num_reemb_var17_hace3', 'num_reemb_var17_ult1', 'num_reemb_var33_hace3', 'num_reemb_var33_ult1', 'num_trasp_var17_in_hace3', 'num_trasp_var17_out_hace3', 'num_trasp_var17_out_ult1', 'num_trasp_var33_in_hace3', 'num_trasp_var33_out_hace3', 'num_trasp_var33_out_ult1', 'num_venta_var44_hace3', 'saldo_var2_ult1', 'saldo_medio_var13_medio_hace2', 'saldo_medio_var13_medio_hace3', 'saldo_medio_var13_medio_ult1', 'saldo_medio_var13_medio_ult3', 'saldo_medio_var29_hace2', 'saldo_medio_var29_hace3']\n",
      "0    7000\n",
      "Name: ind_var2_0, dtype: int64\n",
      "0    7000\n",
      "Name: ind_var13_medio, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- We can see there are 86 features/columns having constant value. This mean they have same value in all samples.\n",
    "- Lets print constant feature names.\n",
    "\"\"\"\n",
    "constCol=[col for col in X_train.columns if col not in X_train.columns[s]]\n",
    "print(constCol)\n",
    "\n",
    "print(X_train['ind_var2_0'].value_counts())\n",
    "print(X_train['ind_var13_medio'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before drop:  (7000, 370) (3000, 370)\n",
      "Shape after drop:  (7000, 284) (3000, 284)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Constant features do not play any role in predicting the result. \n",
    "So we will remove it from our training set and test set.\n",
    "\"\"\"\n",
    "print('Shape before drop: ', X_train.shape, X_test.shape)\n",
    "\n",
    "\"\"\"\n",
    "Transform will remove all the constant columns from training set and test set\n",
    "but we will not use it because it will transform a dataframe to numpy array. \n",
    "\"\"\"\n",
    "# X_train = f_sel.transform(X_train)\n",
    "# X_test = f_sel.transform(X_test)\n",
    "\n",
    "X_train.drop(columns=constCol, axis=1, inplace=True)\n",
    "X_test.drop(columns=constCol, axis=1, inplace=True)\n",
    "\n",
    "print('Shape after drop: ', X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
